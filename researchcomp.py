import time
import re
import csv
import math
from typing import List, Dict, Any, Tuple
import requests
import pandas as pd
import streamlit as st
from tqdm import tqdm

st.set_page_config(page_title="Company Web Check (CVC / LP / Synergy)", layout="wide")

API_KEY = st.secrets["GOOGLE_API_KEY"]
CSE_ID  = st.secrets["GOOGLE_CSE_ID"]

# -------------------------
# Google Custom Search
# -------------------------
SEARCH_ENDPOINT = "https://www.googleapis.com/customsearch/v1"

@st.cache_data(show_spinner=False)
def google_search(query: str, num: int = 5, lang: str = "ja") -> List[Dict[str, Any]]:
    """Call Custom Search API. Cached to save quota."""
    params = {
        "key": API_KEY,
        "cx": CSE_ID,
        "q": query,
        "num": min(max(num, 1), 10),  # APIã®1å›å½“ãŸã‚Šæœ€å¤§10
        "hl": lang,
        "lr": "lang_ja" if lang == "ja" else None,
        "safe": "off",
    }
    # remove None
    params = {k: v for k, v in params.items() if v is not None}
    r = requests.get(SEARCH_ENDPOINT, params=params, timeout=20)
    r.raise_for_status()
    data = r.json()
    return data.get("items", []) or []

# -------------------------
# åˆ¤å®šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆè¶…ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ï¼‰
# -------------------------
def hit(text: str, patterns: List[str]) -> bool:
    t = text.lower()
    return any(p.lower() in t for p in patterns)

def score_from_results(items: List[Dict[str, Any]], must: List[str], any_of: List[str]) -> Tuple[float, str]:
    """ã‚¿ã‚¤ãƒˆãƒ«+ã‚¹ãƒ‹ãƒšãƒƒãƒˆã‚’èµ°æŸ»ã—ã¦ç°¡æ˜“ã‚¹ã‚³ã‚¢ã¨æ ¹æ‹ URLã‚’è¿”ã™"""
    best = (0.0, "")
    for it in items:
        title = it.get("title", "")
        snippet = it.get("snippet", "")
        url = it.get("link", "")
        text = f"{title}\n{snippet}"
        must_ok = all(hit(text, [m]) for m in must) if must else True
        any_ok  = hit(text, any_of) if any_of else True
        base = 0.0
        if must_ok and any_ok:
            base = 0.9
        elif must_ok or any_ok:
            base = 0.6
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ãŒå…¬å¼/PRç³»ãªã‚‰ä¸Šç©ã¿
        if re.search(r"(ir\.|prtimes|newsroom|press|release|investor|corp|company)", url.lower()):
            base += 0.05
        if base > best[0]:
            best = (min(base, 1.0), url)
    return best

def judge_cvc(company: str, lang="ja") -> Tuple[str, int, str]:
    q = f'"{company}" (CVC OR "corporate venture capital" OR Ventures OR ãƒ™ãƒ³ãƒãƒ£ãƒ¼ã‚º OR ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ãƒˆãƒ™ãƒ³ãƒãƒ£ãƒ¼ã‚­ãƒ£ãƒ”ã‚¿ãƒ«)'
    items = google_search(q, num=8, lang=lang)
    score, url = score_from_results(
        items,
        must=[company],
        any_of=["CVC","corporate venture capital","ventures","ãƒ™ãƒ³ãƒãƒ£ãƒ¼ã‚º","ã‚³ãƒ¼ãƒãƒ¬ãƒ¼ãƒˆãƒ™ãƒ³ãƒãƒ£ãƒ¼"]
    )
    return ("Yes" if score >= 0.75 else "Maybe" if score >= 0.6 else "No", round(score*100), url)

def judge_lp(company: str, lang="ja") -> Tuple[str, int, str]:
    q = f'"{company}" ("limited partner" OR LPå‡ºè³‡ OR LPæŠ•è³‡ OR "committed as LP" OR ãƒ•ã‚¡ãƒ³ãƒ‰å‡ºè³‡)'
    items = google_search(q, num=8, lang=lang)
    score, url = score_from_results(
        items,
        must=[company],
        any_of=["limited partner","LPå‡ºè³‡","LPæŠ•è³‡","LPã¨ã—ã¦","ãƒ•ã‚¡ãƒ³ãƒ‰ã¸å‡ºè³‡","å‡ºè³‡ã‚’æ±ºå®š","committed as LP"]
    )
    return ("Yes" if score >= 0.75 else "Maybe" if score >= 0.6 else "No", round(score*100), url)

def judge_synergy(company: str, theme: str, lang="ja") -> Tuple[str, int, str]:
    if theme == "AI/Robotics":
        any_of = ["AI","äººå·¥çŸ¥èƒ½","ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹","ãƒ­ãƒœãƒƒãƒˆ","ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³","ç”ŸæˆAI","æ©Ÿæ¢°å­¦ç¿’","automation","robotics"]
    elif theme == "Healthcare":
        any_of = ["ãƒ˜ãƒ«ã‚¹ã‚±ã‚¢","åŒ»ç™‚","ãƒ¡ãƒ‰ãƒ†ãƒƒã‚¯","ãƒ‡ã‚¸ã‚¿ãƒ«ãƒ˜ãƒ«ã‚¹","ç—…é™¢","è£½è–¬","åŒ»è–¬","biotech","healthcare","medtech"]
    elif theme == "Climate tech":
        any_of = ["ã‚¯ãƒ©ã‚¤ãƒ¡ãƒ¼ãƒˆãƒ†ãƒƒã‚¯","è„±ç‚­ç´ ","å†ç”Ÿå¯èƒ½ã‚¨ãƒãƒ«ã‚®ãƒ¼","æ°´ç´ ","ãƒãƒƒãƒ†ãƒªãƒ¼","CCUS","ã‚«ãƒ¼ãƒœãƒ³","å†ã‚¨ãƒ",
                  "climate tech","decarbonization","renewable","hydrogen","battery","carbon capture","sustainability"]
    else:
        any_of = []

    q = f'"{company}" (partnership OR ææº OR å”æ¥­ OR å…±åŒé–‹ç™º OR investment OR å‡ºè³‡ OR è²·å) ' + " ".join(any_of[:4])
    items = google_search(q, num=8, lang=lang)
    score, url = score_from_results(
        items,
        must=[company],
        any_of=any_of + ["ææº","å”æ¥­","å…±åŒ","å‡ºè³‡","buy","acquire","investment","partnership"]
    )
    return ("Likely" if score >= 0.7 else "Possible" if score >= 0.55 else "Unclear", round(score*100), url)

# -------------------------
# UI
# -------------------------
st.title("ğŸ¢ Company Web Checkï¼ˆCVC / LP / Synergy åˆ¤å®šï¼‰")

st.markdown(
    "- å…¥åŠ›ï¼šExcelï¼ˆCåˆ—=ä¼šç¤¾åï¼‰\n"
    "- å‡ºåŠ›ï¼šCSVï¼ˆåˆ¤å®šãƒ»ä¿¡é ¼åº¦ãƒ»æ ¹æ‹ URLï¼‰\n"
    "- æ¤œç´¢APIï¼šGoogle Custom Search"
)

uploaded = st.file_uploader("Excel / CSV ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["xlsx","csv"])
lang = st.selectbox("æ¤œç´¢è¨€èª", ["ja","en"], index=0)
throttle_ms = st.slider("æ¤œç´¢ã‚¹ãƒ­ãƒƒãƒˆãƒªãƒ³ã‚°ï¼ˆãƒŸãƒªç§’/ã‚¯ã‚¨ãƒªï¼‰", 0, 2000, 200)

if uploaded:
    if uploaded.name.endswith(".csv"):
        df = pd.read_csv(uploaded)
    else:
        df = pd.read_excel(uploaded)

    # Cåˆ—ã‚’ä½¿ã†ï¼ˆ3åˆ—ç›®ï¼‰ã€‚åˆ—æ•°ä¸è¶³ã«å‚™ãˆãŸä¿é™ºã€‚
    if df.shape[1] < 3:
        st.error("ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ã¯Cåˆ—ãŒã‚ã‚Šã¾ã›ã‚“ã€‚Cåˆ—ã«ä¼šç¤¾åã‚’å…¥ã‚Œã¦å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
        st.stop()

    companies = df.iloc[:, 2].dropna().astype(str).tolist()

    st.write(f"èª­ã¿è¾¼ã¿ä»¶æ•°ï¼š{len(companies)} ä»¶ï¼ˆå…ˆé ­5ä»¶è¡¨ç¤ºï¼‰")
    st.dataframe(pd.DataFrame({"company": companies[:5]}))

    if st.button("åˆ¤å®šã‚’é–‹å§‹"):
        rows = []
        pbar = st.progress(0)
        total = len(companies)

        for i, company in enumerate(companies, start=1):
            try:
                cvc, cvc_conf, cvc_url = judge_cvc(company, lang=lang)
                lp,  lp_conf,  lp_url  = judge_lp(company, lang=lang)
                ai,  ai_conf,  ai_url  = judge_synergy(company, "AI/Robotics", lang=lang)
                hc,  hc_conf,  hc_url  = judge_synergy(company, "Healthcare",  lang=lang)
                cl,  cl_conf,  cl_url  = judge_synergy(company, "Climate tech", lang=lang)

                rows.append({
                    "Company": company,
                    "CVC": cvc, "CVC_confidence": cvc_conf, "CVC_evidence": cvc_url,
                    "LP_investor": lp, "LP_confidence": lp_conf, "LP_evidence": lp_url,
                    "AI/Robotics_synergy": ai, "AI_confidence": ai_conf, "AI_evidence": ai_url,
                    "Healthcare_synergy": hc, "Healthcare_confidence": hc_conf, "Healthcare_evidence": hc_url,
                    "ClimateTech_synergy": cl, "Climate_confidence": cl_conf, "Climate_evidence": cl_url,
                })
            except requests.HTTPError as e:
                rows.append({
                    "Company": company, "Error": f"HTTPError {e.response.status_code}", 
                })
            except Exception as e:
                rows.append({
                    "Company": company, "Error": str(e),
                })

            pbar.progress(i/total)
            time.sleep(throttle_ms/1000.0)

        result_df = pd.DataFrame(rows)
        st.success("è§£æå®Œäº†ï¼CSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚")
        st.dataframe(result_df.head(20))

        csv_bytes = result_df.to_csv(index=False).encode("utf-8-sig")  # Excelã§æ–‡å­—åŒ–ã‘ã—ãªã„BOMä»˜
        st.download_button(
            "çµæœCSVã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv_bytes,
            file_name="company_webcheck_result.csv",
            mime="text/csv",
        )

st.caption("â€»åˆ¤å®šã¯ç°¡æ˜“ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã§ã™ã€‚é‡è¦åˆ¤æ–­ã¯åŸå…¸ãƒªãƒ³ã‚¯ã‚’å¿…ãšã”ç¢ºèªãã ã•ã„ã€‚")
