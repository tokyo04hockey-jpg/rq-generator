# streamlit_app.py â€” ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° & ãƒ©ãƒ³ã‚­ãƒ³ã‚°ä»˜ã
import streamlit as st
import requests
import pandas as pd
from urllib.parse import quote
from openai import OpenAI

st.title("ğŸ“ Research Question Generator")
st.write("ãƒ‘ãƒãƒ«/ã‚¤ãƒ³ã‚¿ãƒ“ãƒ¥ãƒ¼è¦ç´„ã‹ã‚‰4è¦–ç‚¹ï¼ˆé€†å¼µã‚Š/é£›ã°ã—/ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•å¹»åƒ/ã‚¢ãƒŠãƒ­ã‚¸ãƒ¼ï¼‰ã§ç ”ç©¶ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆã—ã€"
         "æ–°è¦æ€§Ã—å®Ÿç”¨æ€§ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã—ã¦ãƒ©ãƒ³ã‚­ãƒ³ã‚°ã—ã¾ã™ã€‚")

client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# ========= ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ =========
@st.cache_data(show_spinner=False, ttl=600)
def openalex_count(query: str) -> int:
    # OpenAlex works API: æ¦‚ç®—ä»¶æ•°ã‚’è¿”ã™ï¼ˆæœ€å¤§1ä¸‡ã¾ã§ã—ã‹æ­£ç¢ºã«å‡ºãªã„ãŒæŒ‡æ¨™ã¨ã—ã¦ååˆ†ï¼‰
    url = f"https://api.openalex.org/works?search={quote(query)}&per_page=1"
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        meta = r.json().get("meta", {})
        return int(meta.get("count", 0))
    except Exception:
        return -1  # ã‚¨ãƒ©ãƒ¼æ™‚

def novelty_score_from_count(n: int) -> int:
    # ä»¶æ•°ãŒå°‘ãªã„ã»ã©é«˜ã‚¹ã‚³ã‚¢ï¼ˆ0ã€œ5ï¼‰
    if n < 0:   return 2  # ä¸æ˜ãªã‚‰ä¸­é–“å¯„ã‚Š
    if n < 50:  return 5
    if n < 150: return 4
    if n < 400: return 3
    if n < 1000:return 2
    return 1

def openalex_link(query: str) -> str:
    return f"https://api.openalex.org/works?search={quote(query)}"

def ask_gpt_utility(q: str, context: str) -> dict:
    prompt = f"""
ä»¥ä¸‹ã®ç ”ç©¶ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã«ã¤ã„ã¦ã€ãƒ™ãƒ³ãƒãƒ£ãƒ¼æŠ•è³‡å®¶ãƒ»æ”¿ç­–ç«‹æ¡ˆè€…ã®å®Ÿå‹™ã«ã¨ã£ã¦ã®æœ‰ç”¨æ€§ã‚’5ç‚¹æº€ç‚¹ã§è©•ä¾¡ã—ã€
çŸ­ã„ç†ç”±ã‚’1ã€œ2æ–‡ã§è¿°ã¹ã¦ãã ã•ã„ã€‚JSONã§è¿”ã—ã¦ãã ã•ã„ï¼ˆkeys: score, reasonï¼‰ã€‚

[ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ]
{context}

[ç ”ç©¶ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³]
{q}
"""
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.3,
    )
    txt = resp.choices[0].message.content.strip()
    # ã–ã£ãã‚ŠæŠ½å‡ºï¼ˆå³å¯†ã«JSONã§è¿”ã‚‰ãªã„ã‚±ãƒ¼ã‚¹ã‚‚æƒ³å®šã—ã¦ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰
    import json, re
    try:
        m = re.search(r"\{.*\}", txt, re.S)
        data = json.loads(m.group(0)) if m else {}
        score = int(data.get("score", 3))
        reason = str(data.get("reason", "")).strip()[:200]
    except Exception:
        score, reason = 3, txt[:200]
    score = max(1, min(5, score))
    return {"score": score, "reason": reason}

def generate_rqs(context: str) -> dict:
    prompt = f"""
ä»¥ä¸‹ã®è­°è«–è¦ç´„ã«åŸºã¥ãã€4ã¤ã®è¦–ç‚¹ã§å„1å•ãšã¤ã€æ—¥æœ¬èªã§ç ”ç©¶ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚’ææ¡ˆã—ã¦ãã ã•ã„ã€‚
1. é€†å¼µã‚Šï¼ˆå‰æã‚’é€†ã«è¦‹ã‚‹ï¼‰
2. é£›ã°ã—ï¼ˆæ‰‹æ®µBã‚’å‰æã¨ã›ãšAã‚’é”æˆã™ã‚‹æ–¹æ³•ï¼‰
3. ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¹»æƒ³ï¼ˆAã¨Bã‚’åŒæ™‚é”æˆã§ãã‚‹æ¡ä»¶ï¼‰
4. ã‚¢ãƒŠãƒ­ã‚¸ãƒ¼ï¼ˆä»–åˆ†é‡ã¸ã®è»¢ç”¨ï¼‰

ãã‚Œãã‚Œã€Œè¦‹å‡ºã—ï¼šè³ªå•æ–‡ã€ã®å½¢å¼ã§ç°¡æ½”ã«ã€‚
[è­°è«–è¦ç´„]
{context}
"""
    resp = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.5,
    )
    out = resp.choices[0].message.content.strip()
    # ã‚·ãƒ³ãƒ—ãƒ«ã«è¡Œå˜ä½ã§æ‹¾ã†
    lines = [l.strip("- ").strip() for l in out.splitlines() if l.strip()]
    buckets = {"é€†å¼µã‚Š": "", "é£›ã°ã—": "", "ãƒˆãƒ¬ãƒ¼ãƒ‰ã‚ªãƒ•ã®å¹»æƒ³": "", "ã‚¢ãƒŠãƒ­ã‚¸ãƒ¼": ""}
    for k in list(buckets.keys()):
        for l in lines:
            if l.startswith(k):
                q = l.split("ï¼š", 1)[-1].split(":", 1)[-1].strip()
                buckets[k] = q or l
                break
    # è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°å…ˆé ­ã‹ã‚‰åŸ‹ã‚ã‚‹
    i = 0
    for k in list(buckets.keys()):
        if not buckets[k] and i < len(lines):
            buckets[k] = lines[i]
            i += 1
    return buckets

# ========= UI =========
colA, colB = st.columns([3, 2])
with colB:
    st.markdown("**ã‚¹ã‚³ã‚¢é‡ã¿**")
    w_n = st.slider("æ–°è¦æ€§ã®é‡ã¿", 0.0, 1.0, 0.6, 0.1)
    w_u = 1.0 - w_n
    st.caption(f"ç·åˆç‚¹ = æ–°è¦æ€§Ã—{w_n:.1f} + å®Ÿç”¨æ€§Ã—{w_u:.1f}")

with colA:
    summary = st.text_area("è­°è«–ã®è¦ç´„ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", height=200)

if st.button("ç”Ÿæˆ & ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"):
    if not summary.strip():
        st.warning("å…ˆã«è¦ç´„ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
    else:
        with st.spinner("ç ”ç©¶ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³ã‚’ç”Ÿæˆä¸­..."):
            rqs = generate_rqs(summary)

        rows = []
        with st.spinner("ã‚¹ã‚³ã‚¢ç®—å‡ºä¸­..."):
            for frame, q in rqs.items():
                # æ–°è¦æ€§ï¼ˆOpenAlexä»¶æ•°ï¼‰
                query = q if len(q) > 10 else (summary + " " + q)
                count = openalex_count(query)
                nov = novelty_score_from_count(count)
                link = openalex_link(query)
                # å®Ÿç”¨æ€§ï¼ˆLLMï¼‰
                util = ask_gpt_utility(q, summary)
                score = round(nov * w_n + util["score"] * w_u, 2)
                rows.append({
                    "ç™ºæƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ": frame,
                    "ç ”ç©¶ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³": q,
                    "æ–°è¦æ€§(1-5)": nov,
                    "å®Ÿç”¨æ€§(1-5)": util["score"],
                    "ç·åˆã‚¹ã‚³ã‚¢": score,
                    "å®Ÿç”¨æ€§ã‚³ãƒ¡ãƒ³ãƒˆ": util["reason"],
                    "OpenAlexæ¤œç´¢": link,
                    "ä»¶æ•°(ç›®å®‰)": count if count >= 0 else "N/A",
                })

        df = pd.DataFrame(rows).sort_values("ç·åˆã‚¹ã‚³ã‚¢", ascending=False).reset_index(drop=True)
        st.subheader("ğŸ ãƒ©ãƒ³ã‚­ãƒ³ã‚°")
        st.dataframe(df, use_container_width=True)

        # ä¾¿åˆ©ãƒªãƒ³ã‚¯ã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
        st.markdown("**ğŸ”— ã‚¨ãƒ“ãƒ‡ãƒ³ã‚¹ç¢ºèªï¼ˆOpenAlexï¼‰**ï¼šå„è¡Œã®ãƒªãƒ³ã‚¯ã‹ã‚‰é–¢é€£æ–‡çŒ®ã‚’ç´ æ—©ãç¢ºèªã§ãã¾ã™ã€‚")
        csv = df.to_csv(index=False).encode("utf-8")
        st.download_button("â¬‡ï¸ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=csv, file_name="rq_ranked.csv", mime="text/csv")

        # Markdownç‰ˆï¼ˆãƒ¡ãƒ¢è²¼ã‚Šä»˜ã‘ç”¨ï¼‰
        md = df[["ç™ºæƒ³ãƒ•ãƒ¬ãƒ¼ãƒ ","ç ”ç©¶ã‚¯ã‚¨ã‚¹ãƒãƒ§ãƒ³","æ–°è¦æ€§(1-5)","å®Ÿç”¨æ€§(1-5)","ç·åˆã‚¹ã‚³ã‚¢"]].to_markdown(index=False)
        st.download_button("â¬‡ï¸ Markdownãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰", data=md, file_name="rq_ranked.md", mime="text/markdown")
